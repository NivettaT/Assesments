# -*- coding: utf-8 -*-
"""LVADSUSR101_Nivetta_IAE2_Lab1

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YmjSgGLln58lNxldlNUvgRDF1voSX6KM
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import warnings as wr
wr.filterwarnings("ignore")
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix

# data read
data1 = pd.read_csv("/content/winequality-red.csv")
data1.head()

# basic data1 explr
print("The total number of rows are "+ str(data1.shape[0]))
print("The total number of columns are "+ str(data1.shape[1]))
data1.info()
data1.describe()

# find duplicates
data1.duplicated().sum()
data_no_dup = data1.drop_duplicates()
print("The total number of duplicates dropped are: ",len(data1)-len(data_no_dup))

# Null values
data_no_dup.isnull().sum()
data_no_dup['fixed acidity'].sort_values()
data_no_dup['fixed acidity'] = data_no_dup['fixed acidity'].fillna(method='bfill')
data_no_dup['volatile acidity'].sort_values()
data_no_dup['volatile acidity'] = data_no_dup['volatile acidity'].fillna(method='bfill')
data_no_dup['residual sugar'].sort_values()
data_no_dup['residual sugar'] = data_no_dup['residual sugar'].fillna(method='bfill')
data_no_dup['chlorides'].sort_values()
data_no_dup['chlorides'] = data_no_dup['chlorides'].fillna(method='bfill')
data_no_dup['sulphates'].sort_values()
data_no_dup['sulphates'] = data_no_dup['sulphates'].fillna(method='bfill')
data_no_dup['citric acid'].sort_values()
data_no_dup['citric acid'] = data_no_dup['citric acid'].fillna(method='bfill')
data_no_dup['residual sugar'].sort_values()
data_no_dup['residual sugar'] = data_no_dup['residual sugar'].fillna(method='ffill')
data_no_dup['free sulfur dioxide'].sort_values()
data_no_dup['free sulfur dioxide'] = data_no_dup['free sulfur dioxide'].fillna(method='bfill')
data_no_dup.isnull().sum()

# data outliers
q1 = data_no_dup.quantile(0.25)
q3 = data_no_dup.quantile(0.75)
IQR = q3 - q1
threshold = 1.5
outliers = (data_no_dup < (q1 - threshold * IQR)) | (data_no_dup > (q3 + threshold * IQR))
data = data_no_dup[~outliers.any(axis=1)]
print('Number of outliers removed: ', len(data_no_dup) - len(data))

# basic viz
plt.figure(figsize=(8,6))
sns.countplot(x='quality', data= data, palette = 'rocket')

# dist of attributes
data.hist(figsize=(15, 10), bins=10, xlabelsize=5, ylabelsize=8, color='purple');

columns_to_plot = data.columns
for col in columns_to_plot:
    plt.figure(figsize=(8, 4))
    plt.title(f'Box Plot of {col}')
    sns.boxplot(data=data, x=col, palette="rocket")
    plt.show()

for col in data.columns:
    plot = plt.figure(figsize=(5,5))
    sns.barplot(x='quality', y = col, data = data, palette = 'rocket')

# heatmap viz
plt.figure(figsize=(10,10))
sns.heatmap(data.corr(), cbar = True, fmt = '.1f', annot = True, cmap = 'rocket')

# data transofrmation on the target variable
data['quality'] = data['quality'].apply(lambda x: 'Good' if x in (7, 8) else 'Bad')

le = LabelEncoder()
data['quality'] = le.fit_transform(data['quality'])

# Feature Extraction
X = data.drop('quality', axis =1)
y = data.quality
X

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# knn
knn_classifier = KNeighborsClassifier(n_neighbors=5)
knn_classifier.fit(X_train, y_train)

# rand forest
rf_classifier = RandomForestClassifier()
rf_classifier.fit(X_train, y_train)

# knn evaluation
knn_pred = knn_classifier.predict(X_test)
knn_accuracy = accuracy_score(y_test, knn_pred)
knn_precision = precision_score(y_test, knn_pred)
knn_recall = recall_score(y_test, knn_pred)
knn_confusion_matrix = confusion_matrix(y_test, knn_pred)

# rand forest
rf_pred = rf_classifier.predict(X_test)
rf_accuracy = accuracy_score(y_test, rf_pred)
rf_precision = precision_score(y_test, rf_pred)
rf_recall = recall_score(y_test, rf_pred)
rf_confusion_matrix = confusion_matrix(y_test, rf_pred)

# showing values
print("K-Nearest Neighbors Classifier:")
print("Accuracy:", knn_accuracy)
print("Precision:", knn_precision)
print("Recall:", knn_recall)
print("Confusion Matrix:")
print(knn_confusion_matrix)

print("\n")

print("Random Forest Classifier:")
print("Accuracy:", rf_accuracy)
print("Precision:", rf_precision)
print("Recall:", rf_recall)
print("Confusion Matrix:")
print(rf_confusion_matrix)