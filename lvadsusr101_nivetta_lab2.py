# -*- coding: utf-8 -*-
"""LVADSUSR101_Nivetta_Lab2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wxFAA5c1QWoevat2oCy9bi6OlLwZYlXe
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import warnings as wr
wr.filterwarnings("ignore")

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
# data read
data1 = pd.read_csv('/content/booking.csv')
data1.info()
data1.describe()
data1.head(5)

# duplicate check
dup_no = data1.duplicated().sum()
print('Total number of duplicated records: ', dup_no)
# drop duplicates if exist
data1 = data1.drop_duplicates()

# null check
data1.isnull().sum()
# if null is there, then impute with mean if normally distributed else with median

# outliers check
q1 = data1.quantile(0.25)
q3 = data1.quantile(0.75)
IQR = q3 - q1
threshold = 1.5
outliers = (data1 < (q1 - threshold * IQR)) | (data1 > (q3 + threshold * IQR))
data = data1[~outliers.any(axis=1)]
print('Number of outliers removed: ', len(data1) - len(data))

# Plot histograms for each feature
for i in data.columns:
    plt.figure()
    sns.histplot(data[i], kde=True)
    plt.title(f'Histogram of {i}')
    plt.xlabel(i)
    plt.ylabel('Frequency')
    plt.show()

# corr Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix')
plt.show()

# drop unnecessary columns
data_cleaned = data.drop(['Booking_ID', 'date of reservation'], axis=1)
data_cleaned.head()

# Encode categorical data using Label Encoding
label_encoder = LabelEncoder()
data_cleaned['type of meal'] = label_encoder.fit_transform(data_cleaned['type of meal'])
data_cleaned['room type'] = label_encoder.fit_transform(data_cleaned['room type'])
data_cleaned['market segment type'] = label_encoder.fit_transform(data_cleaned['market segment type'])
data_cleaned['booking status'] = label_encoder.fit_transform(data_cleaned['booking status'])

# extract feature and labels
X = data_cleaned.drop(['booking status'], axis=1)
y = data_cleaned['booking status']

# train test splits
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# model build using Logistic Reg
model = LogisticRegression()
model.fit(X_train, y_train)
pred_lr = model.predict(X_test)

# model build using Logistic Reg
DT = DecisionTreeClassifier()
DT.fit(X_train, y_train)
pred_dt = DT.predict(X_test)

# evaluation metric for log reg
accuracy = accuracy_score(y_test, pred_lr)
precision = precision_score(y_test, pred_lr)
recall = recall_score(y_test, pred_lr)
f1 = f1_score(y_test, pred_lr)
conf_matrix = confusion_matrix(y_test, pred_lr)

# evaluation metric for log reg
accuracy_dt = accuracy_score(y_test, pred_dt)
precision_dt = precision_score(y_test, pred_dt)
recall_dt = recall_score(y_test, pred_dt)
f1_dt = f1_score(y_test, pred_dt)
conf_matrix_dt = confusion_matrix(y_test, pred_dt)

print("Accuracy using logistic reg:", accuracy)
print("Precision using logistic reg:", precision)
print("Recall using logistic reg:", recall)
print("F1 Score using logistic reg:", f1)
print("Confusion Matrix using logistic reg:\n", conf_matrix)

print("Accuracy using decision tree:", accuracy_dt)
print("Precision using decision tree:", precision_dt)
print("Recall using decision tree:", recall_dt)
print("F1 Score using decision tree:", f1_dt)
print("Confusion Matrix using decision tree:\n", conf_matrix_dt)



